{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as dist\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.set_random_seed(2019)\n",
    "np.random.seed(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic:\n",
    "    def __init__(self, sess, obs, acs, hidden_size, name, trainable, init_std=1.0):\n",
    "        self.sess = sess\n",
    "        self.obs = obs\n",
    "        self.acs = acs\n",
    "        self.hidden_size = hidden_size\n",
    "        self.name = name\n",
    "        self.trainable = trainable\n",
    "        self.init_std = init_std\n",
    "\n",
    "        self.num_ac = self.acs.get_shape().as_list()[-1]\n",
    "\n",
    "        with tf.variable_scope(name):\n",
    "            self._build_network()\n",
    "\n",
    "    def _build_network(self):\n",
    "        with tf.variable_scope('critic'):\n",
    "            c_h1 = layers.fully_connected(self.obs, self.hidden_size, trainable=self.trainable)\n",
    "            c_out = layers.fully_connected(c_h1, 1, activation_fn=None, trainable=self.trainable)\n",
    "\n",
    "        with tf.variable_scope('actor'):\n",
    "            a_h1 = layers.fully_connected(self.obs, self.hidden_size, trainable=self.trainable)\n",
    "            a_out = layers.fully_connected(a_h1, self.num_ac, activation_fn=None, trainable=self.trainable)\n",
    "\n",
    "            log_std = tf.get_variable('log_std', [1, self.num_ac], dtype=tf.float32,\n",
    "                                      initializer=tf.constant_initializer(self.init_std),\n",
    "                                      trainable=self.trainable)\n",
    "\n",
    "        std = tf.exp(log_std)\n",
    "        a_dist = dist.Normal(a_out, std)\n",
    "        self.log_prob = a_dist.log_prob(self.acs)\n",
    "        self.entropy = tf.reduce_mean(a_dist.entropy())\n",
    "\n",
    "        self.value = tf.identity(c_out)\n",
    "        self.action = a_dist.sample()\n",
    "\n",
    "    def params(self):\n",
    "        return tf.global_variables(self.name).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Proximal Policy Optimization Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, sess, ob_shape, ac_shape, lr, hidden_size, eps=0.2, v_coeff=0.5, ent_coeff=0.01):\n",
    "        self.sess = sess\n",
    "        self.ob_shape = ob_shape\n",
    "        self.ac_shape = ac_shape\n",
    "        self.lr = lr\n",
    "        self.hidden_size = hidden_size\n",
    "        self.eps = eps\n",
    "        self.v_coeff = v_coeff\n",
    "        self.ent_coeff = ent_coeff\n",
    "\n",
    "        self._create_ppo_graph()\n",
    "\n",
    "    def _create_ppo_graph(self):\n",
    "        self.obs = tf.placeholder(dtype=tf.float32, shape=[None] + self.ob_shape, name='observation')\n",
    "        self.acs = tf.placeholder(dtype=tf.float32, shape=[None] + self.ac_shape, name='action')\n",
    "        self.returns = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "        self.advs = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "\n",
    "        self.pi = ActorCritic(self.sess, self.obs, self.acs, self.hidden_size, 'new_pi', trainable=True)\n",
    "        self.old_pi = ActorCritic(self.sess, self.obs, self.acs, self.hidden_size, 'old_pi', trainable=False)\n",
    "\n",
    "        self.pi_param = self.pi.params()\n",
    "        self.old_pi_param = self.old_pi.params()\n",
    "\n",
    "        with tf.name_scope('update_old_policy'):\n",
    "            self.oldpi_update = [oldp.assign(p) for p, oldp in zip(self.pi_param, self.old_pi_param)]\n",
    "\n",
    "        with tf.name_scope('loss'):\n",
    "            ratio = tf.exp(self.pi.log_prob - self.old_pi.log_prob)\n",
    "            surr = ratio * self.advs\n",
    "            self.actor_loss = tf.reduce_mean(\n",
    "                tf.minimum(surr, tf.clip_by_value(ratio, 1 - self.eps, 1 + self.eps) * self.advs))\n",
    "            self.critic_loss = tf.reduce_mean(tf.square(self.returns - self.pi.value))\n",
    "\n",
    "            self.loss = (- self.actor_loss - self.ent_coeff * tf.reduce_mean(self.pi.entropy)\n",
    "                         + self.v_coeff * self.critic_loss)\n",
    "\n",
    "            with tf.variable_scope('train_op'):\n",
    "                grads = tf.gradients(self.loss, self.pi_param)\n",
    "                self.grads = list(zip(grads, self.pi_param))\n",
    "                self.train_op = tf.train.AdamOptimizer(self.lr).apply_gradients(self.grads)\n",
    "                                                                                #global_step=self.global_step)\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        return self.sess.run(self.pi.action, feed_dict={self.obs: obs})\n",
    "\n",
    "    def get_value(self, obs):\n",
    "        return self.sess.run(self.pi.value, feed_dict={self.obs: obs})\n",
    "\n",
    "    def assign_old_pi(self):\n",
    "        self.sess.run(self.oldpi_update)\n",
    "\n",
    "    def update(self, obs, acs, returns, advs):\n",
    "        feed_dict = {self.obs: obs,\n",
    "                     self.acs: acs,\n",
    "                     self.returns: returns,\n",
    "                     self.advs: advs\n",
    "                     }\n",
    "\n",
    "        self.sess.run(self.train_op, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo_iter(mini_batch_size, obs, acs, returns, advantage):\n",
    "    batch_size = obs.shape[0]\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield (obs[rand_ids, :], acs[rand_ids, :],\n",
    "               returns[rand_ids, :], advantage[rand_ids, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_env(model, vis=False):\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        if vis:\n",
    "            env.render()\n",
    "        ac = model.get_action([ob])[0]\n",
    "        next_ob, reward, done, _ = env.step(ac)\n",
    "        ob = next_ob\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "lr = 3e-4\n",
    "num_steps = 20\n",
    "mini_batch_size = 5\n",
    "ppo_epochs = 4\n",
    "threshold_reward = -200\n",
    "\n",
    "max_frames = 15000\n",
    "frame_idx  = 0\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ob_shape = list(envs.observation_space.shape)\n",
    "ac_shape = list(envs.action_space.shape)\n",
    "\n",
    "ob = envs.reset()\n",
    "early_stop = False\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "ppo = PPO(sess, ob_shape, ac_shape, lr, hidden_size)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "while frame_idx < max_frames and not early_stop:\n",
    "\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    obs = []\n",
    "    acs = []\n",
    "    rewards = []\n",
    "    masks = []\n",
    "    entropy = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "\n",
    "        ac = ppo.get_action(ob)\n",
    "        next_ob, reward, done, _ = envs.step(ac)\n",
    "\n",
    "        value = ppo.get_value(ob)\n",
    "        values.append(value)\n",
    "        rewards.append(reward[:, np.newaxis])\n",
    "        masks.append((1-done)[:, np.newaxis])\n",
    "\n",
    "        obs.append(ob)\n",
    "        acs.append(ac)\n",
    "\n",
    "        ob = next_ob\n",
    "        frame_idx += 1\n",
    "\n",
    "        if frame_idx % 1000 == 0:\n",
    "            test_reward = np.mean([test_env(ppo) for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(frame_idx, test_rewards)\n",
    "            if test_reward > threshold_reward: early_stop = True\n",
    "\n",
    "    next_value = ppo.get_value(next_ob)\n",
    "    returns = compute_gae(next_value, rewards, masks, values)\n",
    "\n",
    "    returns = np.concatenate(returns)\n",
    "    values = np.concatenate(values)\n",
    "    obs = np.concatenate(obs)\n",
    "    acs = np.concatenate(acs)\n",
    "    advantages = returns - values\n",
    "\n",
    "    ppo.assign_old_pi()\n",
    "    for _ in range(ppo_epochs):\n",
    "        for ob_batch, ac_batch, return_batch, adv_batch in ppo_iter(mini_batch_size, obs, acs, returns, advantages):\n",
    "            ppo.update(ob_batch, ac_batch, return_batch, adv_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 reward: -132.86088658600565\n",
      "episode: 1 reward: -1342.6247535416737\n",
      "episode: 2 reward: -1299.3768682578602\n",
      "episode: 3 reward: -391.82710147541525\n",
      "episode: 4 reward: -252.82331147020074\n",
      "episode: 5 reward: -910.3596241710763\n",
      "episode: 6 reward: -1334.5492224654358\n",
      "episode: 7 reward: -1073.6114277962488\n",
      "episode: 8 reward: -524.1848414088507\n",
      "episode: 9 reward: -503.7502058971767\n",
      "episode: 10 reward: -479.0429701566534\n",
      "episode: 11 reward: -233.98007795224316\n",
      "episode: 12 reward: -975.7412001036387\n",
      "episode: 13 reward: -1129.6434017864278\n",
      "episode: 14 reward: -1357.7284282758997\n",
      "episode: 15 reward: -387.05585242056156\n",
      "episode: 16 reward: -1369.7315386214357\n",
      "episode: 17 reward: -1282.2937387845257\n",
      "episode: 18 reward: -330.823707374724\n",
      "episode: 19 reward: -396.26914644029665\n",
      "episode: 20 reward: -529.865933393029\n",
      "episode: 21 reward: -1364.9940498629248\n",
      "episode: 22 reward: -639.2795842283178\n",
      "episode: 23 reward: -1363.2707065349427\n",
      "episode: 24 reward: -379.4897089169742\n",
      "episode: 25 reward: -653.3400187709611\n",
      "episode: 26 reward: -1350.6171932701125\n",
      "episode: 27 reward: -1308.1182515726757\n",
      "episode: 28 reward: -1352.7579291204067\n",
      "episode: 29 reward: -962.8901894768084\n",
      "episode: 30 reward: -628.525394145999\n",
      "episode: 31 reward: -375.65435195113116\n",
      "episode: 32 reward: -1410.9074271416828\n",
      "episode: 33 reward: -259.92368095715096\n",
      "episode: 34 reward: -1355.764581967648\n",
      "episode: 35 reward: -1254.6526002175938\n",
      "episode: 36 reward: -382.7274345243265\n",
      "episode: 37 reward: -391.7541206596111\n",
      "episode: 38 reward: -910.1651113443759\n",
      "episode: 39 reward: -501.00227348499885\n",
      "episode: 40 reward: -819.0669649003389\n",
      "episode: 41 reward: -1325.1503803353128\n",
      "episode: 42 reward: -1342.43786290455\n",
      "episode: 43 reward: -1352.3560633316515\n",
      "episode: 44 reward: -1290.597472474923\n",
      "episode: 45 reward: -1407.573571498436\n",
      "episode: 46 reward: -522.3843847445551\n",
      "episode: 47 reward: -392.77995700800636\n",
      "episode: 48 reward: -260.90892711659274\n",
      "episode: 49 reward: -484.710715974088\n",
      "episode: 50 reward: -261.2274307361117\n",
      "episode: 51 reward: -1358.0962224986501\n",
      "episode: 52 reward: -359.65800707007907\n",
      "episode: 53 reward: -1380.397986485731\n",
      "episode: 54 reward: -1353.8943561943497\n",
      "episode: 55 reward: -1340.4165908223308\n",
      "episode: 56 reward: -1241.0011956753924\n",
      "episode: 57 reward: -917.9348810461921\n",
      "episode: 58 reward: -1332.3737109017047\n",
      "episode: 59 reward: -1347.4066653454065\n",
      "episode: 60 reward: -1161.5663586824483\n",
      "episode: 61 reward: -1207.8582937537994\n",
      "episode: 62 reward: -1345.9538930908639\n",
      "episode: 63 reward: -1330.117879712512\n",
      "episode: 64 reward: -1326.2916994241798\n",
      "episode: 65 reward: -1311.83357120499\n",
      "episode: 66 reward: -1296.2774504226625\n",
      "episode: 67 reward: -1320.6706692183732\n",
      "episode: 68 reward: -1339.5711952522456\n",
      "episode: 69 reward: -1328.073000760045\n",
      "episode: 70 reward: -1199.3763748008944\n",
      "episode: 71 reward: -480.7667378445461\n",
      "episode: 72 reward: -247.56537439808102\n",
      "episode: 73 reward: -555.798901974156\n",
      "episode: 74 reward: -1321.9370948049893\n",
      "episode: 75 reward: -131.8399392579777\n",
      "episode: 76 reward: -1388.3531876114823\n",
      "episode: 77 reward: -1343.4590717542285\n",
      "episode: 78 reward: -1327.134311701434\n",
      "episode: 79 reward: -515.783314600497\n",
      "episode: 80 reward: -1179.7389633571327\n",
      "episode: 81 reward: -1326.0685106800167\n",
      "episode: 82 reward: -269.0219137922398\n",
      "episode: 83 reward: -293.93747752037007\n",
      "episode: 84 reward: -912.0727436198583\n",
      "episode: 85 reward: -1087.2121775969617\n",
      "episode: 86 reward: -785.7994423117993\n",
      "episode: 87 reward: -1358.7411210573339\n",
      "episode: 88 reward: -1357.3099841083924\n",
      "episode: 89 reward: -1368.0459659126502\n",
      "episode: 90 reward: -1071.911512781192\n",
      "episode: 91 reward: -258.70799651852076\n",
      "episode: 92 reward: -260.3067408960146\n",
      "episode: 93 reward: -1237.0834426342392\n",
      "episode: 94 reward: -1268.2591576391446\n",
      "episode: 95 reward: -1402.0866606450966\n",
      "episode: 96 reward: -1358.2335016271747\n",
      "episode: 97 reward: -1372.8953366807373\n",
      "episode: 98 reward: -491.6510239934472\n",
      "episode: 99 reward: -1262.2945269483396\n",
      "episode: 100 reward: -1380.504761853963\n",
      "episode: 101 reward: -1355.43852421622\n",
      "episode: 102 reward: -1336.5252074953132\n",
      "episode: 103 reward: -1375.76984732411\n",
      "episode: 104 reward: -579.5249114821179\n",
      "episode: 105 reward: -1388.4034373334423\n",
      "episode: 106 reward: -1046.9323219564778\n",
      "episode: 107 reward: -616.1491876309407\n",
      "episode: 108 reward: -1350.366472445182\n",
      "episode: 109 reward: -370.29980468861066\n",
      "episode: 110 reward: -1250.4457847690724\n",
      "episode: 111 reward: -254.17214349144388\n",
      "episode: 112 reward: -1341.5272010251708\n",
      "episode: 113 reward: -1361.3708923090667\n",
      "episode: 114 reward: -508.64043689655864\n",
      "episode: 115 reward: -4.981960560210261\n",
      "episode: 116 reward: -392.7272563964987\n",
      "episode: 117 reward: -1344.9689965407813\n",
      "episode: 118 reward: -1178.5874922078726\n",
      "episode: 119 reward: -1374.794326830807\n",
      "episode: 120 reward: -1367.3714309848954\n",
      "episode: 121 reward: -262.05503603089784\n",
      "episode: 122 reward: -574.4353261330148\n",
      "episode: 123 reward: -393.43601126931026\n",
      "episode: 124 reward: -1240.5636885570607\n",
      "episode: 125 reward: -1353.2011346484462\n",
      "episode: 126 reward: -388.1850783272633\n",
      "episode: 127 reward: -1370.302438474545\n",
      "episode: 128 reward: -1241.5720782797023\n",
      "episode: 129 reward: -1333.1411015519527\n",
      "episode: 130 reward: -1365.5982884858377\n",
      "episode: 131 reward: -1354.8606775350715\n",
      "episode: 132 reward: -362.8790475262447\n",
      "episode: 133 reward: -1050.2821460922912\n",
      "episode: 134 reward: -1293.9691389324014\n",
      "episode: 135 reward: -1352.3653725906065\n",
      "episode: 136 reward: -935.0747894034297\n",
      "episode: 137 reward: -1319.1514759237027\n",
      "episode: 138 reward: -498.6897088025406\n",
      "episode: 139 reward: -794.9149427749612\n",
      "episode: 140 reward: -1030.953829003674\n",
      "episode: 141 reward: -620.3921160793242\n",
      "episode: 142 reward: -1353.5025795672607\n",
      "episode: 143 reward: -1230.6890189102114\n",
      "episode: 144 reward: -1374.0655302083628\n",
      "episode: 145 reward: -1365.8886489185352\n",
      "episode: 146 reward: -1376.7645567915654\n",
      "episode: 147 reward: -1126.5757258309175\n",
      "episode: 148 reward: -1164.762066718535\n",
      "episode: 149 reward: -1373.003487863859\n",
      "episode: 150 reward: -1337.0498485440337\n",
      "episode: 151 reward: -1223.1128779760609\n",
      "episode: 152 reward: -1354.7915539919181\n",
      "episode: 153 reward: -931.5718644119631\n",
      "episode: 154 reward: -681.8059088176458\n",
      "episode: 155 reward: -1315.9049609789818\n",
      "episode: 156 reward: -633.0915854703295\n",
      "episode: 157 reward: -1186.9849021579157\n",
      "episode: 158 reward: -1348.040549076906\n",
      "episode: 159 reward: -1360.4058226612392\n",
      "episode: 160 reward: -1392.529969880511\n",
      "episode: 161 reward: -380.3517744904647\n",
      "episode: 162 reward: -1302.3362520879803\n",
      "episode: 163 reward: -1377.3747974928738\n",
      "episode: 164 reward: -1361.747591312233\n",
      "episode: 165 reward: -1312.8072872906262\n",
      "episode: 166 reward: -390.303816705585\n",
      "episode: 167 reward: -1354.6682091097289\n",
      "episode: 168 reward: -1375.3751278296893\n",
      "episode: 169 reward: -1331.7780184887142\n",
      "episode: 170 reward: -1409.5989977314866\n",
      "episode: 171 reward: -1358.268251743168\n",
      "episode: 172 reward: -1394.422931742079\n",
      "episode: 173 reward: -519.8753029349359\n",
      "episode: 174 reward: -751.2228402247093\n",
      "episode: 175 reward: -1328.228634071158\n",
      "episode: 176 reward: -1350.8855819859302\n",
      "episode: 177 reward: -1363.0340403559057\n",
      "episode: 178 reward: -393.26699010439086\n",
      "episode: 179 reward: -1213.0158462455056\n",
      "episode: 180 reward: -1314.4383011663515\n",
      "episode: 181 reward: -1235.278323662043\n",
      "episode: 182 reward: -1205.5017534171225\n",
      "episode: 183 reward: -516.680822449919\n",
      "episode: 184 reward: -1215.1461473863092\n",
      "episode: 185 reward: -1400.7875172914373\n",
      "episode: 186 reward: -1329.562187410784\n",
      "episode: 187 reward: -1355.9332284402808\n",
      "episode: 188 reward: -501.8884587703966\n",
      "episode: 189 reward: -1370.963818099106\n",
      "episode: 190 reward: -507.4629645131471\n",
      "episode: 191 reward: -1161.6405528767662\n",
      "episode: 192 reward: -1373.9860357429902\n",
      "episode: 193 reward: -790.91312174861\n",
      "episode: 194 reward: -809.6286171196945\n",
      "episode: 195 reward: -945.0201355558925\n",
      "episode: 196 reward: -1254.688678185959\n",
      "episode: 197 reward: -1154.8782411394668\n",
      "episode: 198 reward: -1342.036689181839\n",
      "episode: 199 reward: -974.7427142838706\n",
      "episode: 200 reward: -1361.999064037554\n",
      "episode: 201 reward: -978.0377599408941\n",
      "episode: 202 reward: -132.86138168816666\n",
      "episode: 203 reward: -444.8867979977374\n",
      "episode: 204 reward: -1327.6544193326827\n",
      "episode: 205 reward: -1374.2490836294394\n",
      "episode: 206 reward: -1269.4761321939848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 207 reward: -644.1266421954313\n",
      "episode: 208 reward: -261.49573239088227\n",
      "episode: 209 reward: -1340.5457340598887\n",
      "episode: 210 reward: -1306.330625009011\n",
      "episode: 211 reward: -1353.9875969405834\n",
      "episode: 212 reward: -1104.7281650944144\n",
      "episode: 213 reward: -526.7001498729632\n",
      "episode: 214 reward: -1229.9718644303193\n",
      "episode: 215 reward: -1401.1980827798945\n",
      "episode: 216 reward: -1334.7117169508863\n",
      "episode: 217 reward: -1208.9811418370696\n",
      "episode: 218 reward: -1240.4142282045875\n",
      "episode: 219 reward: -1356.5162352787947\n",
      "episode: 220 reward: -1384.5572429319884\n",
      "episode: 221 reward: -1356.6742711486734\n",
      "episode: 222 reward: -682.4997031834764\n",
      "episode: 223 reward: -1331.8396323130678\n",
      "episode: 224 reward: -475.831738114603\n",
      "episode: 225 reward: -1355.9457198604202\n",
      "episode: 226 reward: -1380.6164070610098\n",
      "episode: 227 reward: -1159.2850714391311\n",
      "episode: 228 reward: -1197.0207458971802\n",
      "episode: 229 reward: -1351.396589396431\n",
      "episode: 230 reward: -1381.8913383358822\n",
      "episode: 231 reward: -826.4364695586659\n",
      "episode: 232 reward: -389.4390302441486\n",
      "episode: 233 reward: -1381.7163296915255\n",
      "episode: 234 reward: -262.7513943090063\n",
      "episode: 235 reward: -546.3437363913923\n",
      "episode: 236 reward: -1329.5583680475615\n",
      "episode: 237 reward: -618.9260510355523\n",
      "episode: 238 reward: -955.7111546294284\n",
      "episode: 239 reward: -428.58588269870717\n",
      "episode: 240 reward: -1414.5365624994415\n",
      "episode: 241 reward: -509.4633974777577\n",
      "episode: 242 reward: -1398.8635483060907\n",
      "episode: 243 reward: -641.4870274019557\n",
      "episode: 244 reward: -1370.6240917779473\n",
      "episode: 245 reward: -1267.8612713053128\n",
      "episode: 246 reward: -961.3719994807932\n",
      "episode: 247 reward: -1080.9420367127314\n",
      "episode: 248 reward: -1326.989395532879\n",
      "episode: 249 reward: -526.4001719138631\n",
      "\n",
      "(50000, 4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        ac = ppo.get_action([ob])[0]\n",
    "        next_ob, reward, done, _ = env.step(ac)\n",
    "        ob = next_ob\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([ob, ac]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
